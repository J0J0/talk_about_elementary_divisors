
\chapter{Der Elementarteilersatz}
\begin{thSatz}[Elementarteilersatz]\label{ets}
    Sei $F$ ein endlich erzeugter freier Modul über einem HIR $R$. Sei außerdem
    $M\subset F$ ein Untermodul. Dann existieren Elemente $x_1,\ldots,x_s\in F$
    und $\alpha_1,\ldots,\alpha_s\in R\setminus\{0\}$ mit folgenden
    Eigenschaften:
    \begin{enumerate}[i)]
        \item
            $x_1,\ldots,x_s$ sind Teil einer Basis von $F$.
        \item
            $\alpha_1 x_1, \ldots, \alpha_s x_s$ bilden eine Basis von $M$.
        \item
            Es gilt für alle $i\in\{1,\ldots,s-1\}$:\; $\alpha_i\mid\alpha_{i+1}$.
    \end{enumerate}
    Außerdem sind die $\alpha_1,\ldots,\alpha_s$ bis auf Assoziiertheit
    eindeutig durch $M$ bestimmt (unabhängig von der Wahl der $x_1,\ldots,x_s$)
    und man nennt diese Elemente dann die \emph{Elementarteiler von 
    $M\subset F$}.
\end{thSatz}

Der Beweis dieses Satzes wird für die Existenz- und Eindeutigkeitsaussage
getrennt geführt und erfordert einigen Aufwand. Es soll hier deshalb nur eine
Beweisskizze gegeben werden, in der die wichtigen Schritte dargestellt werden.
Einen kompletten Beweis nach dem folgenden Schema kann man in 
% TODO: \cite
[TODO]
nachlesen.

\begin{proofsketch}[ zur Existenzaussage]
    Wir wählen zunächst eine Basis $Y = (y_1,\ldots,y_m)$ von~$F$. Per Induktion
    über $m$ zeigt man nun, dass auch jeder Untermodul $M\subset F$ endlich
    erzeugt ist: für $m=0$ ist nichts zu zeigen und für $m=1$ ist die Behauptung
    klar, da dann $F\cong R$ ist und somit gilt, dass $M$ gerade einem Ideal in
    $R$ entspricht, welches aber nach Voraussetzung von einem einzigen Element erzeugt
    wird; Für $m>1$ betrachtet man dann eine geeignete Zerlegung $F = F'
    \oplus F''$, wendet auf $M\cap F'$ und die Projektion von $M$ auf $F''$ die
    Induktionsvoraussetzung an und zeigt dann, dass man als Vereinigung von
    endlichen Erzeugendensystemen dieser beiden Untermoduln ein
    Erzeugendensystem für ganz $M$ erhält.
    
    Da wir nun wissen, dass $M$ endlich erzeugt ist, können wir ein solches
    Erzeugendensystem $z_1,\ldots,z_n$ wählen. Bezeichne weiter $e_1,\ldots,e_n$
    die Standardbasis von $R^n$ als $R$-Modul, so kann man eine lineare
    Abbildung $f$ wie folgt definieren (eindeutig bestimmt, durch die Bilder auf
    der Basis $e_j$%
    % TODO: \cite 06/1.1  "und folgende"
    ):
    \begin{align*}
        f\colon R^n &\to F  \\
        e_j &\mapsto z_j \,, \quad j\in\{1,\ldots,n\}
    \end{align*}
    Da wir auf ein Erzeugendensystem von $M$ abbilden, gilt also
    $\Image(f) = M$. Weiter können wir $f$ bezüglich der Basen $e_1,\ldots,e_n$
    und $Y$ als Matrix $A\in R^{m\times n}$ darstellen, so dass für die
    Matrixelemente $\A ij$ und $j\in\{1,\ldots,n\}$ gilt:
    \[ z_j = \sum_{i=1}^m \A ij y_i \]
    
    Nun verwenden wir die \enquote{Matrixversion des Elementarteilersatzes}
    \pcref{ets:matrix}
    und erhalten somit Matrizen $S\in\mr{GL}(m,R)$ und $T\in\mr{GL}(n,R)$, so
    dass $A' := S\,A\,T$ die im Lemma genannte Form (mit Diagonalelementen
    $\alpha_1,\ldots,\alpha_s$) hat. Nach [TODO] % TODO: \cite 08/1.11
    können wir $S$ und $T$ gerade als Basiswechselmatrizen auffassen und
    wissen somit, dass es Basen $e_1',\ldots,e_n'$ von $R^n$ und
    $x_1,\ldots,x_m$ von $F$ gibt, so dass $A'$ die darstellende Matrix der
    Abbildung $f$ ist. Da sich dadurch natürlich das Bild nicht ändert, erhalten
    wir, dass $\alpha_1 x_1, \ldots, \alpha_n x_s$ ein Erzeugendensystem von $M$
    bilden. Außerdem sind $x_1,\ldots,x_s$ frei und mit der Nullteilerfreiheit
    von $R$ folgt, dass oben genanntes Erzeugendensystem auch frei ist; es
    bildet also sogar eine Basis von $M$.
    \\
\end{proofsketch}

Damit ist nun die Existenz der Elementarteiler $\alpha_1,\ldots,\alpha_s$
bewiesen, falls das nun folgende Lemma gilt, das oben verwendet wurde.

\begin{thLemma}[Elementarteilersatz für Matrizen]\label{ets:matrix}
    Sei $R$ ein HIR und $A = (\A ij)_{ij} \in R^{m\times n}$. Dann gibt es
    Matrizen $S\in\mr{GL}(m,R)$ und $T\in\mr{GL}(n,R)$, so dass gilt:
    \begin{align*}
        S\cdot A\cdot T 
        &= 
        \left( \begin{array}{c|c}
            \mr{diag}(\alpha_1,\ldots,\alpha_s)
            &
            0^{s \times (n-s)}
            \\[3pt] \hline \rule{0pt}{17pt}
            0^{(m-s) \times s}
            &
            0^{(m-s) \times (n-s)}
        \end{array} \right)
        \\[3mm]
        &= \Matrix{
        \alpha_1 & & & & & &   \\ 
        & \alpha_2 & & & & &   \\
        & & \ddots & & & &     \\
        & & & \alpha_s & & &   \\
        & & & &   & &          \\
        & & & & &        &     \\
        & & & & & &           
        }
        \in R^{m\times n}
    \end{align*}
    (In der ersten Darstellung bezeichnet dabei $0^{k\times l}$ die 
    $(k\times l)$-Nullmatrix und in der zweiten seien alle
    nicht explizit gesetzten Elemente gleich $0$.)  \\
    Dabei erfüllen außerdem die Einträge $\alpha_1,\ldots,\alpha_s\in R\setminus\{0\}$
    ($0\leq s\leq \min(m,n)$) für $i\in\{1,\ldots,s-1\}$ die Bedingung:
    $\alpha_i \mid \alpha_{i+1}$. Diese Elemente nennt man dann die
    \emph{Elementarteiler der Matrix~$A$}. (Weiter wird die Form der Matrix
    $SAT$ in der Literatur auch \emph{Smith-Normalform}, insbesondere im
    Englischen \emph{smith normal form}, der Matrix $A$ genannt.)
\end{thLemma}

\begin{proofsketch}[ zur Existenzaussage]
    Man versucht die Matrix $A$ durch elementare Umformungen (ähnlich wie beim
    Gauß-Algorithmus) in die gewünschte Form zu bringen. Jede dieser elementaren
    Umformungen kann durch eine entsprechende Matrix $S'$ oder $T'$ dargestellt
    werden, wodurch klar ist, dass die Existenz der behaupteten Matrizen
    bewiesen ist, sobald durch den Algorithmus die behauptete Form erreicht
    wurde.
    
    Das komplette Verfahren kann in [TODO] % TODO: \cite
    nachgelesen werden. Es sollen hier deswegen nur die nötigen Schritte
    angegeben werden, um es durchzuführen, ohne jedoch allzu genau auf die
    Begründungen einzugehen.
    
    Sei zunächst $R$ ein euklidischer Ring mit Gradfunktion
    $\delta\colon\R\!\setminus\!\{0\}\to\N$. % \cite
    Sei weiter das Minimum aller Grade von Elementen der Matrix $A$ wie folgt
    definiert:
    \[ \D(A) := \min\bigl\{ \delta(\A ij) \;\big\vert\; \A ij\neq0,\;
                            1\leq i\leq m, \; 1\leq j\leq n \bigr\}    \]
    Führe nun folgenden Algorithmus durch:
    \begin{enumerate}[1.]
        \item[0.]
            Ist $A=0$, so sind wir fertig, denn es ist nichts zu zeigen;
            der Algorithmus bricht also ab.
            Für $A\neq0$ existiert dann aber $\D(A)$, wie oben definiert, und
            wir können fortfahren.
            
        \item 
            Ist $\D(A) \neq \delta(\A11)$, so tausche Spalten und Zeilen
            derart, dass Gleichheit gilt.
            
        \item
            Gibt es nun ein $\A1j$ (mit $2\leq j\leq n$), so dass 
            $\A11 \nmid \A1j$, so existieren Elemente $q,r\in R$ mit $\A1j =
            q\A11 + r$, wobei $\delta(r) < \delta(\A11)$. Ziehe dann das
            $q$-fache der ersten Spalte von der $j$-ten Spalte ab, dann ist das
            neue $\A1j$ gleich $r$. Starte nun wieder bei 1.
            
            Gehe analog auch für die Elemente $\A i1$ vor.
            
            Bei jeder Durchführung dieses Schritts wird aber $\D(A)$ verringert,
            welches aber nur Werte in $\N$ annehmen kann, so dass der Prozess
            also nach endlich vielen Schritten abbrechen muss. Gehe dann über
            zum nächsten Schritt.
            
        \item
            Nun gilt also $\A11 \mid \A1j$ und $\A11 \mid \A i1$ für alle
            $2\leq i\leq m,\; 2\leq j\leq n$. Durch Subtraktion der entsprechenden
            Vielfachen, erreichen wir also sogar $\A 1j = \A i1 = 0$ für
            $2\leq i\leq m$, $2\leq j\leq n$.
            
        \item
            Teilt nun $\A11$ sogar alle anderen Elemente $\neq 0$ der Matrix, so
            beginne den kompletten Algorithmus erneut mit der Teilmatrix von
            $A$, die man durch Streichen der ersten Zeile und Spalte erhält.
            Alle verwendeten Operationen erhalten die Eigenschaft, dass $\A11$
            die übrigen Elemente teilt, so dass wir dann induktiv fertig sind.
            
            Gibt es aber $1<i\leq m,\; 1<j\leq n$ mit $\A11 \nmid \A ij$, so
            addiere einfach die $i$-te Zeile zur ersten (was $\A11$ unverändert
            lässt) und durchlaufe dann den Algorithmus erneut. Weil wieder
            $\D(A)$ verringert wird, muss auch dieser Prozess nach endlich
            vielen Schritten enden und es gilt dann der vorherige Absatz.
    \end{enumerate}
    Insgesamt erhalten wir also nach endlich vielen Schritten die gewünschte
    Matrix.
    
    Haben wir nun statt eines euklidischen Rings nur einen HIR, so ist das
    Verfahren nicht ganz so anschaulich, weitestgehend aber analog: wir nehmen
    als $\delta$ die Abbildung, die jedem Element aus $R$ die Anzahl seiner
    Primfaktoren zuordnet. Weiter müssen wir -- am Punkt $\A11 \nmid \A1j$ --
    das \enquote{Teilen mit Rest} durch Bilden von 
    $\beta := \mr{ggT}(\A11,\A1j)$ ersetzen und können dann mit Hilfe einer
    geeigneten Operation erreichen, dass wir statt $\A11$ gerade $\beta$ in
    der Matrix bekommen. Mit $\delta(\beta) < \delta(\A11)$ verringert sich also
    wieder das Minimum $\D(A)$ und das restliche Verfahren läuft analog ab. Die
    Details können in [TODO] % TODO: \cite
    nachgeschlagen werden.
    
    Damit sei nun also die Existenzaussage des Lemmas und damit auch die von
    \cref{ets} gezeigt.
    \\
\end{proofsketch}

Nun wissen wir, dass die Elementarteiler existieren. Es fehlt aber noch der
Beweis zur Eindeutigkeitsaussage im Elementarteilersatz. Dazu zeigen wir
folgendes Lemma, wofür wir die eingangs eingeführte Länge $\len$ brauchen
werden:

\begin{thLemma}\label{lem:iso:divisors:unique}
    Sei $R$ ein HIR und es gelte
    \[ Q \cong \bigoplus_{i=1}^s R/\alpha_i R \,, \]
    mit $\alpha_1,\ldots,\alpha_s \in R\setminus (R^\times\cup\{0\})$, wobei
    $R^\times$ die Einheitengruppe von $R$ bezeichne, und
    $\alpha_i\mid\alpha_{i+1}$ für $i\in\{1,\ldots,s-1\}$.
    Dann sind $\alpha_1,\ldots,\alpha_s$ bis auf Assoziiertheit eindeutig durch
    $Q$ bestimmt.
\end{thLemma}

\begin{proof}
    Aus Notationsgründen invertieren wir die Nummerierung der $\alpha_i$,
    so dass dann also $\alpha_{i+1} \mid \alpha_i$ für $i\in\{1,\ldots,s-1\}$
    gilt. Betrachte dann zwei Zerlegungen
    \[ Q \cong 
        \bigoplus_{i=1}^s R/\alpha_i R \cong \bigoplus_{j=1}^t R/\beta_j R \,,\]
    die beide die obigen Forderungen erfüllen.
    
    Falls es nun einen Index $k\in\{1,\ldots,\min(s,t)\}$ mit
    $\alpha_k R \neq \beta_k R$ gibt, so wähle $k$ minimal mit dieser
    Eigenschaft. Da $\alpha_k$ von $\alpha_{k+1},\ldots,\alpha_s$ geteilt wird,
    hat man für $l\in\{k,\ldots,s\}$:
    \[ \alpha_k (R/\alpha_l R) = 0 \]
    Also erhalten wir für $\alpha_k Q$:
    \begin{align*}
        \alpha_k Q 
        &\cong      \bigoplus_{i=1}^{k-1} \alpha_k (R/\alpha_i R) \oplus
        \underbrace{\bigoplus_{i=k}^{s}   \alpha_k (R/\alpha_i R)}_{= 0}  \\
        &\cong \bigoplus_{i=1}^{k-1} \alpha_k (R/\alpha_i R) \oplus
               \bigoplus_{j=k}^{t}   \alpha_k (R/\beta_j R)
    \end{align*}
    
    Wegen \cref{lem:len:hir} und \cref{lem:len:add}
    wissen wir, dass $\len(Q)$ endlich ist und damit natürlich auch
    $\len(\alpha_k Q) \leq \len(Q)$. Vergleichen wir nun also die Längen der
    beiden Zerlegungen in obiger Gleichung, so erhalten wir:
    \begin{align*}
        & &
        \len\biggl(\; \bigoplus_{i=1}^{k-1} \alpha_k (R/\alpha_i R) \biggr)
        &= \len\biggl(\; \bigoplus_{i=1}^{k-1} \alpha_k (R/\alpha_i R) \oplus
                         \bigoplus_{j=k}^{t}   \alpha_k (R/\beta_j R) \biggr)
        \\[1mm]
        &\overset{ \ref{lem:len:add} }{\implies}\quad &
        \sum_{i=1}^{k-1} \len\bigl(\alpha_k (R/\alpha_i R)\bigr)
        &= \sum_{i=1}^{k-1} \len\bigl(\alpha_k (R/\alpha_i R)\bigr)
         + \sum_{j=k}^{t}   \len\bigl(\alpha_k (R/\beta_j R) \bigr)
        \\[1mm]
        &\overset{ \ref{lem:len:hir} }{\implies}\quad &
        0 &= \sum_{j=k}^{t} \len\bigl(\alpha_k (R/\beta_j R) \bigr)
    \end{align*}
    Also muss schon $\len\bigl(\alpha_k (R/\beta_j R) \bigr) = 0$ für alle
    $j\in\{k,\ldots,t\}$ sein. Das ist aber gleichbedeutend mit 
    $\alpha_k (R/\beta_j R) = 0$; insbesondere folgt für $j=k$, dass $\alpha_k R \subset
    \beta_k R$ sein muss. Mit dem umgekehrten Argument für die Zerlegung erhält
    man analog: $\beta_k R \subset \alpha_k R$. 
    Also wäre $\alpha_k R = \beta_k R$, was einen Widerspruch bedeutet. Es
    gilt somit $\alpha_i R = \beta_i R$ für alle $i\in\{1,\ldots,\min(s,t)\}$.
    
    Nehme nun an, dass $s<t$ gilt, dann folgt mit demselben Schluss wie oben,
    dass
    \[ \sum_{j=s+1}^{t} \len\bigl( R/\beta_j R \bigr) = 0   \quad
        \implies\quad \len\bigl(R/\beta_j R\bigr) = 0,\; j\in\{s+1,\ldots,t\} 
    . \]
    Dies ist aber ein Widerspruch dazu, dass für die Nichteinheit $\beta_j$ der
    Restklassenmodul $R/\beta_j R$ eine Länge größer $0$ haben muss.
    Analog führt man $t>s$ zum Widerspruch und man erhält somit $s=t$.
    \\
\end{proof}

\begin{proof}[Beweis der Eindeutigkeitsaussage in \cref{ets}]
    Sei dazu $x_1,\ldots,x_m$ eine Basis von $F$ und\\
    $\alpha_1 x_1,\ldots,\alpha_s x_s$ eine Basis von $M$ mit
    $\alpha_i\mid\alpha_{i+1}$ für alle $i\in\{1,\ldots,s-1\}$.
    
    Betrachte nun den Untermodul $F'\subset F$, der wie folgt definiert ist:
    \[ F' := \bigoplus_{i=1}^s Rx_i 
        = \bigl\{ y\in F \;\big\vert\; \exists \lambda\in R\setminus\{0\}\colon
        \; \lambda y \in M \bigr\}  \]
    Durch die zweite Charakterisierung wird klar, dass $F'$ nicht von der Wahl
    der Elemente $x_1,\ldots,x_s$ abhängt.
    Bilde dann den kanonischen Homomorphismus
    \begin{align*}
        F' &\to \bigoplus_{i=1}^s R/\alpha_i R      \\
        y' = \sum_{i=1}^s a_ix_i &\mapsto (\bar{a}_1,\ldots,\bar{a}_s) \,,
    \end{align*}
    der offenbar surjektiv ist und $M$ als Kern besitzt. 
    Mit dem Homomorphiesatz % TODO: \cite !?
    folgt dann ein (eindeutiger) $R$-Modulhomomorphismus:
    \[ F'/M \overset\sim\to \bigoplus_{i=1}^s R/\alpha_i R \]
    Nach \cref{lem:iso:divisors:unique}
    sind damit alle Nicht-Einheiten unter den $\alpha_i$ bis auf Assoziiertheit 
    eindeutig bestimmt. Nach [TODO] % TODO: \cite 03/3.6
    haben alle Basen von $M$ die gleiche Länge $s$. Somit ist klar, dass dann
    auch die Zahl der Einheiten unter den $\alpha_i$ eindeutig bestimmt ist.
    Insgesamt gilt also die Eindeutigkeit von $\alpha_1,\ldots,\alpha_s$ (bis
    auf Assoziiertheit), wie behauptet.
    \\
\end{proof}

\begin{thKorollar}[Eindeutigkeitsaussage in \cref{ets:matrix}]
    Die Eindeutigkeit der Elementarteiler in \cref{ets:matrix}
    folgt unmittelbar aus der soeben bewiesenen Eindeutigkeit der
    Elementarteiler in \cref{ets}.
\end{thKorollar}

Damit sind wir mit dem Beweis des Elementarteilersatzes (und der
\enquote{Matrixversion}) fertig. Wir fassen noch einmal zusammen, dass wir uns
auch in der Situation von \cref{ets}
auf das konstruktive Verfahren, das in der Beweisskizze zu \cref{ets:matrix}
gegeben wurde, beziehen können, um konkret die Elementarteiler eines Untermoduls
zu bestimmen:

\begin{thKorollar}
    Seien $F,F'$ endlich erzeugte freie Moduln über einem HIR $R$ und sei weiter
    $M\subset F$ ein Untermodul von $F$. Dann ist $M$ endlich erzeugt und für
    eine $R$-lineare Abbildung $f\colon F'\to F$, die eine Basis von $F'$ auf
    ein Erzeugendensystem von $M$ abbildet, gilt: Ist $A$ eine Matrixdarstellung
    von $f$ bezüglich Basen von $F'$ und $F$, so stimmen die Elementarteiler der
    Matrix $A$ mit denen des Untermoduls $M$ überein.
\end{thKorollar}








